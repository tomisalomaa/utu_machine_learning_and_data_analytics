{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "ADA2021_exercise1_template.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_yJ68z8SM89"
      },
      "source": [
        "Tomi Salomaa <br>\n",
        "student number <br>\n",
        "  <br>\n",
        "January, 31, 2021  <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7hsMPkfSM9C"
      },
      "source": [
        "# Exercise 1 | TKO_2096 Application of Data Analysis 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwQRbPEUSM9C"
      },
      "source": [
        "#### Nested cross-validation for K-nearest neighbors <br>\n",
        "- Use Python 3 to program a nested cross-validation for the k-nearest neighbors (kNN) method so that the number of neighbours k is automatically selected from the range 1 to 10. In other words, the base learning algorithm is kNN but the actual learning algorithm, whose prediction performance will be evaluated with nested CV, is kNN with automatic CV-based model selection (see the lectures and the pseudo codes presented on them for more info on this interpretation).\n",
        "- As a kNN implementation, you can use sklearn: http://scikit-learn.org/stable/modules/neighbors.html but your own kNN implementation can also be used if you like to keep more control on what is happening in the learning process. The CV implementation should be easily modifiable, since the forthcoming exercises involve different problem-dependent CV variations.\n",
        "- Use the nested CV implementation on the iris data and report the resulting classification accuracy. Hint: you can use the nested CV example provided on sklearn documentation: https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html as a starting point and compare your nested CV implementation with that but do NOT use the ready made CV implementations of sklearn as the idea of the exercise is to learn to split the data on your own. The other exercises need more sophisticated data splitting which are not necessarily available in libraries.\n",
        "- Return your solution for each exercise BOTH as a Jupyter Notebook file and as a PDF-file made from it.\n",
        "- Return the report to the course page on **Monday 1st of February** at the latest.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yH1dNenSM9D"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_3-e2kKSM9D"
      },
      "source": [
        "#In this cell import all libraries you need. For example: \n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets, metrics\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from random import randrange, seed"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXO0boRFbLDp"
      },
      "source": [
        "## Methods for the complete approach below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLbFxqt6xeD3"
      },
      "source": [
        "# Load iris dataset and separate to features and (numerical) labels\r\n",
        "# Form a collective dataset to use later\r\n",
        "irisData = datasets.load_iris()\r\n",
        "X_iris = irisData.data\r\n",
        "y_iris = irisData.target\r\n",
        "iris_collective = [None]*len(X_iris)\r\n",
        "\r\n",
        "for i in range (0,len(X_iris)):\r\n",
        "  iris_collective[i] = np.append(X_iris[i], y_iris[i])"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iAaloy0z8eeI",
        "outputId": "4e1e88b3-5540-4f32-95a1-2d52d3825cb2"
      },
      "source": [
        "# Just a check to see the arrays are correct\r\n",
        "print(X_iris[0])\r\n",
        "print(y_iris[0])\r\n",
        "print(iris_collective[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.1 3.5 1.4 0.2]\n",
            "0\n",
            "[5.1 3.5 1.4 0.2 0. ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su7sli_ADPWF"
      },
      "source": [
        "# Cross validation split method\r\n",
        "# !!! DOES NOT stratify, only pops randomly !!!\r\n",
        "#\r\n",
        "# Defaults the amount of folds to 10 if not spesicied otherwise.\r\n",
        "# Defines fold element size by dividing the parameter dataset length\r\n",
        "# with parameter folds and returns the resulting split as a list of arrays.\r\n",
        "def cross_validation_split(dataset, folds=10):\r\n",
        "  dataset_split = list()\r\n",
        "  dataset_copy = list(dataset)\r\n",
        "  fold_size = int(len(dataset) / folds)\r\n",
        "  for i in range(folds):\r\n",
        "    fold = list()\r\n",
        "    while len(fold) < fold_size:\r\n",
        "      index = randrange(len(dataset_copy))\r\n",
        "      fold.append(dataset_copy.pop(index))\r\n",
        "    dataset_split.append(fold)\r\n",
        "  return dataset_split"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ7yJKYr50bR"
      },
      "source": [
        "# Inner cross validation loop.\r\n",
        "#\r\n",
        "# Inspired by https://towardsdatascience.com/build-knn-from-scratch-python-7b714c47631a\r\n",
        "# and modded to work with the numpy array setup used in this excercise.\r\n",
        "#\r\n",
        "# Splits the given dataset by using cross_validation_split method with\r\n",
        "# user defined parameters.\r\n",
        "# Creates a scikit knn classifier with neighbours of n 1-10,\r\n",
        "# fits and saves the mean accuracy score of each classifier,\r\n",
        "# after which returns the best observed neighbour amount\r\n",
        "# based on the mean scores of the classifiers.\r\n",
        "def cross_validation_inner(dataset, folds):\r\n",
        "  folds = cross_validation_split(dataset, folds)\r\n",
        "  mean_scores = []\r\n",
        "  absolute_scores = []\r\n",
        "  result = []\r\n",
        "  \r\n",
        "  # perform loop for each k value between [1-10]\r\n",
        "  for i in range (1,11):\r\n",
        "    scores = []\r\n",
        "    knn = KNeighborsClassifier(n_neighbors=i)\r\n",
        "    \r\n",
        "    # For given k value between 1-10, go through splitting to train and valuate.\r\n",
        "    # The construct of outer method is used here so valuate is still named as\r\n",
        "    # test_set.\r\n",
        "    for fold in range (len(folds)):\r\n",
        "      train_set = list(folds)\r\n",
        "      train_set.pop(fold)\r\n",
        "      train_set = sum(train_set, [])\r\n",
        "      test_set = list()\r\n",
        "\r\n",
        "      for arr in folds[fold]:\r\n",
        "        arr_copy = list(arr)\r\n",
        "        test_set.append(arr_copy)\r\n",
        "\r\n",
        "      # Building y_ and x_ train/test arrays and fitting the knn classifier.\r\n",
        "      y_train = [arr[-1] for arr in train_set]\r\n",
        "      x_train = [train[:-1] for train in train_set]\r\n",
        "      knn.fit(x_train, y_train)\r\n",
        "      y_test = [arr[-1] for arr in test_set]\r\n",
        "      x_test = [test[:-1] for test in test_set]\r\n",
        "\r\n",
        "      # Scoring by accuracy\r\n",
        "      acc = knn.score(x_test, y_test)\r\n",
        "      scores.append(acc)\r\n",
        "    \r\n",
        "    absolute_scores.append(scores)\r\n",
        "    mean_scores.append(np.mean(scores))\r\n",
        "  \r\n",
        "  # Checks which index has the highest mean score.\r\n",
        "  # Since the k values are tested in order, the index value can also\r\n",
        "  # be used to define the k value.\r\n",
        "  # For information purposes additional data is returned as results also.\r\n",
        "  result.append(np.argmax(mean_scores)+1)\r\n",
        "  result.append(absolute_scores)\r\n",
        "  result.append(mean_scores)\r\n",
        "\r\n",
        "  return result"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QW2I2y8XaHkN"
      },
      "source": [
        "# Nested cross validation (or the outer loop).\r\n",
        "# Splits the given dataset and feeds each fold to the inner loop\r\n",
        "# to receive the best observed neighbour amount. Uses this value\r\n",
        "# for the scikit knn classifier.\r\n",
        "#\r\n",
        "# This method is in many ways similar to the inner method. Look for\r\n",
        "# cross_validation_inner() above for further comments.\r\n",
        "def cross_validation_nested(dataset, outer_folds=10, inner_folds=5):\r\n",
        "  folds = cross_validation_split(dataset, outer_folds)\r\n",
        "  scores = []\r\n",
        "  neighbours = []\r\n",
        "  inner_scores_absolute = []\r\n",
        "  inner_scores_mean = []\r\n",
        "  \r\n",
        "  for fold in range (len(folds)):\r\n",
        "    train_set = list(folds)\r\n",
        "    train_set.pop(fold)\r\n",
        "    train_set = sum(train_set, [])\r\n",
        "    test_set = list()\r\n",
        "\r\n",
        "    for arr in folds[fold]:\r\n",
        "      arr_copy = list(arr)\r\n",
        "      test_set.append(arr_copy)\r\n",
        "\r\n",
        "    # Set the observed best neighbour k value as a parameter for knn and save\r\n",
        "    # other inner results for later presenting.\r\n",
        "    results_from_inner = cross_validation_inner(train_set, inner_folds)\r\n",
        "    neighbours.append(results_from_inner[0])\r\n",
        "    inner_scores_absolute.append(results_from_inner[1])\r\n",
        "    inner_scores_mean.append(results_from_inner[2])\r\n",
        "    knn = KNeighborsClassifier(n_neighbors = results_from_inner[0])\r\n",
        "    \r\n",
        "    y_train = [arr[-1] for arr in train_set]\r\n",
        "    x_train = [train[:-1] for train in train_set]\r\n",
        "    knn.fit(x_train, y_train)\r\n",
        "    y_test = [arr[-1] for arr in test_set]\r\n",
        "    x_test = [test[:-1] for test in test_set]\r\n",
        "    acc = knn.score(x_test, y_test)\r\n",
        "    scores.append(acc)\r\n",
        "  \r\n",
        "  present_mean_scores = np.mean(scores)\r\n",
        "  present_scores = np.around(scores, decimals = 5)\r\n",
        "\r\n",
        "  print('-'*42)\r\n",
        "  print('OVERALL MEAN ACCURACY:',present_mean_scores)\r\n",
        "  print('-'*42)\r\n",
        "  print('\\nFold spesific info for',outer_folds,'outer folds and',inner_folds,\r\n",
        "        'inner folds.')\r\n",
        "  print('*'*60)\r\n",
        "  for i in range (0,len(scores)):\r\n",
        "    print('Fold',i+1,'>>','Score:',present_scores[i],'with k =',neighbours[i])\r\n",
        "    for j in range (0,len(inner_scores_absolute[i])):\r\n",
        "      print('   Inner fold',j+1,'>>','Absolute scores:',inner_scores_absolute[i][j])\r\n",
        "      print('   Inner fold',j+1,'>>','Mean score:',inner_scores_mean[i][j])"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ0CZ8nJSM9E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c0d46f83-a42c-41a9-909c-bb3c00d4bcf3"
      },
      "source": [
        "#In this cell run your script for nested CV and print the result.\r\n",
        "cross_validation_nested(iris_collective, 5, 10)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------\n",
            "OVERALL MEAN ACCURACY: 0.9533333333333334\n",
            "------------------------------------------\n",
            "\n",
            "Fold spesific info for 5 outer folds and 10 inner folds.\n",
            "************************************************************\n",
            "Fold 1 >> Score: 0.96667 with k = 6\n",
            "   Inner fold 1 >> Absolute scores: [1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.9166666666666666]\n",
            "   Inner fold 1 >> Mean score: 0.9666666666666666\n",
            "   Inner fold 2 >> Absolute scores: [1.0, 0.9166666666666666, 1.0, 0.9166666666666666, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.9166666666666666]\n",
            "   Inner fold 2 >> Mean score: 0.9583333333333333\n",
            "   Inner fold 3 >> Absolute scores: [1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0]\n",
            "   Inner fold 3 >> Mean score: 0.975\n",
            "   Inner fold 4 >> Absolute scores: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0]\n",
            "   Inner fold 4 >> Mean score: 0.9833333333333334\n",
            "   Inner fold 5 >> Absolute scores: [1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0]\n",
            "   Inner fold 5 >> Mean score: 0.975\n",
            "   Inner fold 6 >> Absolute scores: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 1.0]\n",
            "   Inner fold 6 >> Mean score: 0.9916666666666666\n",
            "   Inner fold 7 >> Absolute scores: [1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 1.0]\n",
            "   Inner fold 7 >> Mean score: 0.9833333333333332\n",
            "   Inner fold 8 >> Absolute scores: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 1.0]\n",
            "   Inner fold 8 >> Mean score: 0.9916666666666666\n",
            "   Inner fold 9 >> Absolute scores: [1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.9166666666666666]\n",
            "   Inner fold 9 >> Mean score: 0.9666666666666666\n",
            "   Inner fold 10 >> Absolute scores: [1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 1.0, 1.0]\n",
            "   Inner fold 10 >> Mean score: 0.975\n",
            "Fold 2 >> Score: 0.93333 with k = 1\n",
            "   Inner fold 1 >> Absolute scores: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.9166666666666666, 0.9166666666666666]\n",
            "   Inner fold 1 >> Mean score: 0.9666666666666666\n",
            "   Inner fold 2 >> Absolute scores: [1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.9166666666666666, 0.9166666666666666]\n",
            "   Inner fold 2 >> Mean score: 0.9583333333333333\n",
            "   Inner fold 3 >> Absolute scores: [1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.8333333333333334, 0.9166666666666666, 0.9166666666666666]\n",
            "   Inner fold 3 >> Mean score: 0.9583333333333333\n",
            "   Inner fold 4 >> Absolute scores: [1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.8333333333333334, 0.9166666666666666, 0.9166666666666666]\n",
            "   Inner fold 4 >> Mean score: 0.95\n",
            "   Inner fold 5 >> Absolute scores: [1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.8333333333333334, 0.9166666666666666, 0.9166666666666666]\n",
            "   Inner fold 5 >> Mean score: 0.9583333333333333\n",
            "   Inner fold 6 >> Absolute scores: [1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666]\n",
            "   Inner fold 6 >> Mean score: 0.9499999999999998\n",
            "   Inner fold 7 >> Absolute scores: [1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.8333333333333334, 0.9166666666666666, 0.9166666666666666]\n",
            "   Inner fold 7 >> Mean score: 0.9499999999999998\n",
            "   Inner fold 8 >> Absolute scores: [1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666]\n",
            "   Inner fold 8 >> Mean score: 0.9499999999999998\n",
            "   Inner fold 9 >> Absolute scores: [1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666]\n",
            "   Inner fold 9 >> Mean score: 0.9583333333333333\n",
            "   Inner fold 10 >> Absolute scores: [1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666]\n",
            "   Inner fold 10 >> Mean score: 0.9499999999999998\n",
            "Fold 3 >> Score: 1.0 with k = 9\n",
            "   Inner fold 1 >> Absolute scores: [0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 1.0, 0.9166666666666666, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0]\n",
            "   Inner fold 1 >> Mean score: 0.95\n",
            "   Inner fold 2 >> Absolute scores: [0.9166666666666666, 1.0, 0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 0.8333333333333334, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 2 >> Mean score: 0.9416666666666667\n",
            "   Inner fold 3 >> Absolute scores: [0.9166666666666666, 0.9166666666666666, 0.9166666666666666, 1.0, 0.9166666666666666, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0]\n",
            "   Inner fold 3 >> Mean score: 0.95\n",
            "   Inner fold 4 >> Absolute scores: [0.9166666666666666, 1.0, 0.9166666666666666, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0]\n",
            "   Inner fold 4 >> Mean score: 0.9666666666666666\n",
            "   Inner fold 5 >> Absolute scores: [0.9166666666666666, 1.0, 0.9166666666666666, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0]\n",
            "   Inner fold 5 >> Mean score: 0.9666666666666666\n",
            "   Inner fold 6 >> Absolute scores: [0.9166666666666666, 1.0, 0.9166666666666666, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 6 >> Mean score: 0.9583333333333333\n",
            "   Inner fold 7 >> Absolute scores: [0.9166666666666666, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 7 >> Mean score: 0.9666666666666666\n",
            "   Inner fold 8 >> Absolute scores: [0.9166666666666666, 1.0, 1.0, 1.0, 0.8333333333333334, 0.9166666666666666, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 8 >> Mean score: 0.9583333333333333\n",
            "   Inner fold 9 >> Absolute scores: [1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 9 >> Mean score: 0.975\n",
            "   Inner fold 10 >> Absolute scores: [1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.9166666666666666, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 10 >> Mean score: 0.9666666666666666\n",
            "Fold 4 >> Score: 0.96667 with k = 3\n",
            "   Inner fold 1 >> Absolute scores: [1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 0.8333333333333334, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 1 >> Mean score: 0.9583333333333333\n",
            "   Inner fold 2 >> Absolute scores: [1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 0.8333333333333334, 0.9166666666666666, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 2 >> Mean score: 0.95\n",
            "   Inner fold 3 >> Absolute scores: [1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.8333333333333334, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 3 >> Mean score: 0.9666666666666666\n",
            "   Inner fold 4 >> Absolute scores: [1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 0.9166666666666666, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 4 >> Mean score: 0.9666666666666666\n",
            "   Inner fold 5 >> Absolute scores: [1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 0.9166666666666666, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 5 >> Mean score: 0.9666666666666666\n",
            "   Inner fold 6 >> Absolute scores: [1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 0.9166666666666666, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 6 >> Mean score: 0.9666666666666666\n",
            "   Inner fold 7 >> Absolute scores: [1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 0.8333333333333334, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 7 >> Mean score: 0.9583333333333333\n",
            "   Inner fold 8 >> Absolute scores: [0.9166666666666666, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 0.8333333333333334, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 8 >> Mean score: 0.95\n",
            "   Inner fold 9 >> Absolute scores: [0.9166666666666666, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 0.8333333333333334, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 9 >> Mean score: 0.95\n",
            "   Inner fold 10 >> Absolute scores: [0.9166666666666666, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0, 0.8333333333333334, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 10 >> Mean score: 0.95\n",
            "Fold 5 >> Score: 0.9 with k = 6\n",
            "   Inner fold 1 >> Absolute scores: [1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0]\n",
            "   Inner fold 1 >> Mean score: 0.9583333333333333\n",
            "   Inner fold 2 >> Absolute scores: [1.0, 0.9166666666666666, 0.75, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0]\n",
            "   Inner fold 2 >> Mean score: 0.95\n",
            "   Inner fold 3 >> Absolute scores: [1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0]\n",
            "   Inner fold 3 >> Mean score: 0.975\n",
            "   Inner fold 4 >> Absolute scores: [0.9166666666666666, 1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0]\n",
            "   Inner fold 4 >> Mean score: 0.9666666666666666\n",
            "   Inner fold 5 >> Absolute scores: [1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0]\n",
            "   Inner fold 5 >> Mean score: 0.975\n",
            "   Inner fold 6 >> Absolute scores: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0]\n",
            "   Inner fold 6 >> Mean score: 0.9833333333333332\n",
            "   Inner fold 7 >> Absolute scores: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 0.9166666666666666, 1.0]\n",
            "   Inner fold 7 >> Mean score: 0.9833333333333332\n",
            "   Inner fold 8 >> Absolute scores: [1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 8 >> Mean score: 0.9833333333333332\n",
            "   Inner fold 9 >> Absolute scores: [1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 9 >> Mean score: 0.9833333333333332\n",
            "   Inner fold 10 >> Absolute scores: [1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0]\n",
            "   Inner fold 10 >> Mean score: 0.9833333333333332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2yB4SJfStrv"
      },
      "source": [
        "<h3>Thoughts and analysis of the task:</h3>\r\n",
        "<p>\r\n",
        "With a busy couple of weeks a decision to use scikit's available KNN-classifier was made to reduce potential errors present from a self-made original KNN-algorithm. Creating such an algorithm would be an interesting challenge, though and will most likely be done later.\r\n",
        "</p>\r\n",
        "<p>\r\n",
        "The concrete outcome of this task were the two cross validation methods which when used together formed a nested cross validation approach to choosing and evaluating the optimal parameter value for KNN neighbors. Along these two methods a third method was created for splitting the data to be used for cross validation.\r\n",
        "</p>\r\n",
        "<p>\r\n",
        "Some problems / thoughts for the general functionality of the proposed solution rose up during the programming process:\r\n",
        "<ul>\r\n",
        "<li>Currently the use of KNN classifier is deeply integrated within the cross validation solution. For the task at hand this works but in general the CV approach should be model agnostic and just execute the validation.</li>\r\n",
        "<li>Splitting of the dataset to be used should be possible with stratifying. Currently randomness is used to perform the split. With a few test runs this seemed to work ok but it is reasonable to note that the iris dataset has 1:1:1 relation with target classes; random split probably won't do if the dataset is imbalanced target-wise.</li>\r\n",
        "<li>The inner CV performs folds the same way as the outer (though fold amounts can be specified through parameters). LOOCV was thought of as a possibility for inner CV approach and probably this should be coded as an option to the proposed solution.</li>\r\n",
        "</ul>\r\n",
        "</p>\r\n",
        "<p>\r\n",
        "Overall the nested cross validation seemed to give out mean values that were a bit on the high end. If this is due to poor splitting / handling of the data I am uncertain as similar results seemed to be reported with Iris dataset from what could be gathered on some outside sources (so perhaps the approach itself with nested CV and KNN just works well with the dataset). Though, it is highly possible that the code makes overfitting possible / handles train & test datasets incorrectly. To be honest, much of the brain resources were used to learning Python while attempting to grasp the solution as well, so something may have slipped between fingers.\r\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBRzZBkmRIL7"
      },
      "source": [
        "<h3>Used outside references and sources beside lectures:</h3>\r\n",
        "<p>\r\n",
        "https://towardsdatascience.com/build-knn-from-scratch-python-7b714c47631a<br/>\r\n",
        "https://towardsdatascience.com/implementing-k-nearest-neighbors-with-scikit-learn-9e4858e231ea<br/>\r\n",
        "https://towardsdatascience.com/complete-guide-to-pythons-cross-validation-with-examples-a9676b5cac12<br/>\r\n",
        "https://machinelearningmastery.com/nested-cross-validation-for-machine-learning-with-python/<br/>\r\n",
        "https://machinelearningmastery.com/implement-resampling-methods-scratch-python/\r\n",
        "</p>"
      ]
    }
  ]
}